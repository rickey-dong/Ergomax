{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pose_quality_assessment_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO590K521FotU2J3bFvSuA/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickey-dong/Ergomax/blob/main/pose_quality_assessment_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9rqqJEMjCtR",
        "outputId": "15bb5e94-3160-4135-ae44-962485c30bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "from numpy.linalg import norm"
      ],
      "metadata": {
        "id": "DcKJ45X-jZMi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
        "movenet = model.signatures['serving_default']"
      ],
      "metadata": {
        "id": "37MLHXWojfDT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOSE = 0\n",
        "LEFT_EYE = 1\n",
        "RIGHT_EYE = 2\n",
        "LEFT_EAR = 3\n",
        "RIGHT_EAR = 4\n",
        "LEFT_SHOULDER = 5\n",
        "RIGHT_SHOULDER = 6\n",
        "Y = 0\n",
        "X = 1\n",
        "CONFIDENCE_VALUE = 2\n",
        "CONFIDENCE_THRESHOLD = 0.26"
      ],
      "metadata": {
        "id": "eAuH4dX-njYf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_extraction(image_file):\n",
        "    \"\"\"\n",
        "    takes in an image\n",
        "    and\n",
        "    returns a list of relevant landmarks\n",
        "    with y, x, and confidence values\n",
        "    \"\"\"\n",
        "\n",
        "    # run the model!\n",
        "    outputs = movenet(image_file)\n",
        "\n",
        "    keypoints = outputs['output_0'].numpy()\n",
        "\n",
        "    # converting this 4-layered array into something more manageable\n",
        "    # i don't think we're too comfortable working with numpy so maybe\n",
        "    # better to convert\n",
        "    cleaner_2d_array = [ [0]*3 for i in range(7) ]\n",
        "    body_part = 0\n",
        "    for ary0 in keypoints:\n",
        "        for ary1 in ary0:\n",
        "            while body_part < 7:\n",
        "                index = 0\n",
        "                for num in keypoints[0][0][body_part]:\n",
        "                    cleaner_2d_array[body_part][index] = num\n",
        "                    index += 1\n",
        "                body_part += 1\n",
        "\n",
        "    return cleaner_2d_array\n",
        "\n",
        "def calculate_cosine_similarity(ideal, current):\n",
        "    ideal_1D = []\n",
        "    for body_point in ideal:\n",
        "      ideal_1D.append(body_point[1]) # x value\n",
        "      ideal_1D.append(body_point[0]) # y value\n",
        "    \n",
        "    current_1D = []\n",
        "    for body_point in current:\n",
        "      current_1D.append(body_point[1])\n",
        "      current_1D.append(body_point[0])\n",
        "  \n",
        "    A = np.array(ideal_1D)\n",
        "    B = np.array(current_1D)\n",
        "    cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
        "    return cosine\n",
        "  \n",
        "def check_head_tilt(current):\n",
        "    # if eyes are at ear level, then head is tilted\n",
        "    if current[LEFT_EYE][Y] > current[LEFT_EAR][Y] + 0.10:\n",
        "      return False\n",
        "    if current[RIGHT_EYE][Y] > current[RIGHT_EAR][Y] + 0.10:\n",
        "      return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "HDwyz474jl26"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_rickey = \"\"\"\n",
        "0.51898634 0.5141955 0.60066235 \n",
        "0.46213895 0.5748569 0.8942077 \n",
        "0.46386486 0.45547873 0.8542165 \n",
        "0.5035565 0.6509616 0.5807533 \n",
        "0.51048446 0.37870285 0.7500463 \n",
        "0.78193563 0.7620751 0.5300895 \n",
        "0.7900616 0.30074388 0.65386754\n",
        "\"\"\"\n",
        "\n",
        "baseline_rickey_array = [[0.51898634, 0.5141955, 0.60066235], [0.46213895, 0.5748569, 0.8942077], [0.46386486, 0.45547873, 0.8542165], [0.5035565, 0.6509616, 0.5807533], [0.51048446, 0.37870285, 0.7500463], [0.78193563, 0.7620751, 0.5300895], [0.7900616, 0.30074388, 0.65386754]]\n",
        "\n",
        "slouch_rickey = \"\"\"\n",
        "0.59844774 0.519061 0.40708265 \n",
        "0.5301816 0.59195983 0.8289351 \n",
        "0.5341892 0.45447135 0.4498962 \n",
        "0.57492197 0.67865723 0.6057053 \n",
        "0.5780213 0.3705523 0.5283152 \n",
        "0.7645539 0.8212724 0.2530607 \n",
        "0.7899105 0.28375655 0.25369805\n",
        "\"\"\"\n",
        "\n",
        "current_rickey_array = [[0.59844774, 0.519061, 0.40708265], [0.5301816, 0.59195983, 0.8289351], [0.5341892, 0.45447135, 0.4498962], [0.57492197, 0.67865723, 0.6057053], [0.5780213, 0.3705523, 0.5283152], [0.7645539, 0.8212724, 0.2530607], [0.7899105, 0.28375655, 0.25369805]]\n",
        "\n",
        "slouch_rickey_tilted_head = \"\"\"\n",
        "0.6696064 0.533864 0.71748036 \n",
        "0.6088849 0.5900854 0.73862654 \n",
        "0.6069633 0.47765368 0.6631635 \n",
        "0.60519946 0.6635702 0.43899816 \n",
        "0.60147464 0.4105199 0.5412193 \n",
        "0.8310034 0.7259691 0.3184248 \n",
        "0.83240736 0.34737605 0.37198436\n",
        "\"\"\"\n",
        "\n",
        "slouch_rickey_tilted_head_array = [[0.6696064, 0.533864, 0.71748036], [0.6088849, 0.5900854, 0.73862654], [0.6069633, 0.47765368, 0.6631635], [0.60519946, 0.6635702, 0.43899816], [0.60147464, 0.4105199, 0.5412193], [0.8310034, 0.7259691, 0.3184248], [0.83240736, 0.34737605, 0.37198436]]\n"
      ],
      "metadata": {
        "id": "iqFnR1P5kLYw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# baseline = tf.io.read_file(\"baseline-rickey.jpg\")\n",
        "# baseline = tf.compat.v1.image.decode_jpeg(baseline)\n",
        "# baseline = tf.expand_dims(baseline, axis=0)\n",
        "# baseline = tf.cast(tf.image.resize_with_pad(baseline, 192, 192), dtype=tf.int32)\n",
        "\n",
        "# baseline_array = feature_extraction(baseline)\n",
        "# for row in baseline_rickey_array:\n",
        "#   string = \"\"\n",
        "#   for number in row:\n",
        "#     string += str(number)\n",
        "#     string += \" \"\n",
        "#   print(string)\n",
        "\n",
        "# current = tf.io.read_file(\"slouch-rickey.jpg\")\n",
        "# current = tf.compat.v1.image.decode_jpeg(current)\n",
        "# current = tf.expand_dims(current, axis=0)\n",
        "# current = tf.cast(tf.image.resize_with_pad(current, 192, 192), dtype=tf.int32)\n",
        "\n",
        "# current_array = feature_extraction(current)\n",
        "\n",
        "# tilted = tf.io.read_file(\"slouch-rickey-tilted-head.jpg\")\n",
        "# tilted = tf.compat.v1.image.decode_jpeg(tilted)\n",
        "# tilted = tf.expand_dims(tilted, axis=0)\n",
        "# tilted = tf.cast(tf.image.resize_with_pad(tilted, 192, 192), dtype=tf.int32)\n",
        "\n",
        "# slouch_rickey_tilted_head = feature_extraction(tilted)\n",
        "\n",
        "# for row in slouch_rickey_tilted_head:\n",
        "#   string = \"\"\n",
        "#   for number in row:\n",
        "#     string += str(number)\n",
        "#     string += \" \"\n",
        "#   print(string)\n",
        "\n",
        "# print(slouch_rickey_tilted_head)"
      ],
      "metadata": {
        "id": "nus9c4vxjtLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def has_bad_posture(ideal, current):\n",
        "    \"\"\"\n",
        "    takes in two lists of keypoints and confidence values\n",
        "    returns true if user has bad posture currently,\n",
        "    false otherwise\n",
        "    \"\"\"\n",
        "    # useful articles?\n",
        "    # https://medium.com/roonyx/pose-estimation-and-matching-with-tensorflow-lite-posenet-model-ea2e9249abbd\n",
        "    # https://medium.com/@priyaanka.garg/comparison-of-human-poses-with-posenet-e9ffc36b7427\n",
        "    if current[NOSE][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[LEFT_EYE][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[RIGHT_EYE][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[LEFT_EAR][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[RIGHT_EAR][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[LEFT_SHOULDER][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD or \\\n",
        "        current[RIGHT_SHOULDER][CONFIDENCE_VALUE] < CONFIDENCE_THRESHOLD:\n",
        "            # if the model is less than 26% confident about the location of any\n",
        "            # particular body point, then there's not enough data to make a guess\n",
        "            # or could mean that the user is severely slouching and has most of the\n",
        "            # body off camera\n",
        "            return 'NOT ENOUGH DATA'\n",
        "    cos_sim = calculate_cosine_similarity(ideal, current)\n",
        "    print(cos_sim)\n",
        "    if cos_sim < 0.4:\n",
        "      return 'NOT SIMILAR POSTURE'\n",
        "    if check_head_tilt(current) == True:\n",
        "      return 'HEAD TILTED'\n",
        "    # if current body landmarks y-coords are greater than the baseline,\n",
        "    # then that means the landmarks are further down than ideal, so could\n",
        "    # be indicative of slouching\n",
        "    # if ((current[LEFT_SHOULDER][Y] >= ideal[LEFT_SHOULDER][Y] + 0.01) or (current[RIGHT_SHOULDER][Y] >= ideal[RIGHT_SHOULDER][Y] + 0.01)):\n",
        "    #     return 'BAD POSTURE 0'\n",
        "    # if ((current[LEFT_EAR][Y] >= ideal[LEFT_EAR][Y] + 0.01) or (current[RIGHT_EAR][Y] >= ideal[RIGHT_EAR][Y] + 0.01)):\n",
        "    #     return 'BAD POSTURE 1'\n",
        "    return 'NICE'\n"
      ],
      "metadata": {
        "id": "JU7bYNVGnnZh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(has_bad_posture(baseline_rickey_array, slouch_rickey_tilted_head_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsRCqOUFoL7T",
        "outputId": "bb5d60b6-e224-47ae-8c30-c1f9729532a4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.994963661516067\n",
            "HEAD TILTED\n"
          ]
        }
      ]
    }
  ]
}